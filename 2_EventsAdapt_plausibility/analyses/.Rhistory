data = data %>%
filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
View(data)
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#filter for US, English, na, and duplicate, then get scores
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "yes" &
Answer.profcheck2 == "yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating))
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "yes" &
Answer.profcheck2 == "yes" &
TrialType != "filler" &
n <= num.trials)
rlang::last_error()
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
# Answer.profcheck1 == "yes" &
# Answer.profcheck2 == "yes" &
TrialType != "filler" &
n <= num.trials)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),starts_with('WorkerId')
-Input.list,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#filter for US, English, na, and duplicate, then get scores
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
# Answer.profcheck1 == "yes" &
# Answer.profcheck2 == "yes" &
TrialType != "filler" &
n <= num.trials)
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "yes" &
Answer.profcheck2 == "yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating))
View(data.good)
View(data)
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "Yes" &
Answer.profcheck2 == "Yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating))
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),starts_with('WorkerId')
-Input.list,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
View(data)
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'))
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#filter for US, English, na, and duplicate, then get scores
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "Yes" &
Answer.profcheck2 == "Yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating))
View(data.good)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "Yes" &
Answer.profcheck2 == "Yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating)) %>%
select(-Answer.English, -Answer.country, -Answer.profcheck1, -Answer.profcheck2,
-na.pct, -n)
data.good.summary = data.good %>%
group_by(Item, Plausibility, Voice)
View(data.good.summary)
data.good.summary = data.good %>%
group_by(Item, Plausibility, Voice) %>%
summarize(
m = mean(Answer.Rating),
stdev= sd(Answer.Rating),
#    se = stdev/sqrt(n()),
#    upper= m+se*1.96,
#    lower=m-se*1.96
)
source('D:/git/beh-ratings-events/2_EventsAdapt_plausibility/analyses/analyze_subjects.R', echo=TRUE)
data_summ = merge(data_summ, checksdf, by="WorkerId")
source('D:/git/beh-ratings-events/2_EventsAdapt_plausibility/analyses/analyze_subjects.R', echo=TRUE)
write_csv(data,"good_data.csv")
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
## SAVE A LONGFORM VERSION OF YOUR DATA
write_csv(data,"longform_data.csv")
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
#
# data_summ = data %>%
#   group_by(WorkerId) %>%
#   summarize(
#     na.pct = mean(is.na(Answer.Rating)),
#     n = length(Answer.Rating))
#
# data_byplausibility = data %>%
#   group_by(WorkerId, Plausibility) %>%
#   summarise_at(c("Answer.Rating"), funs(mean(., na.rm=TRUE)))
## save a summary of individual subjects' performance
# write_csv(data_summ,"data_summ_by_worker.csv")
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#filter for US, English, na, and duplicate, then get scores
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "Yes" &
Answer.profcheck2 == "Yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating)) %>%
select(-Answer.English, -Answer.country, -Answer.profcheck1, -Answer.profcheck2,
-na.pct, -n)
write_csv(data,"good_data.csv")
write_csv(data.good,"good_data.csv")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'))
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'))
# checksdf = data %>% select(starts_with('WorkerId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.profcheck1', 'Answer.profcheck2',
'WorkTimeInSeconds', 'Answer.answer'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
# data = data %>%
#   filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
## save a summary of individual subjects' performance
write_csv(data_summ,"data_summ_by_worker.csv")
View(data)
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',)))                   # bad responses
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results.csv',
'../results_raw/Batch_4368386_batch_results.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers (note: currently done manually)
data = data %>%
filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
'A2717S28QHY09K')))                   # bad responses
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
## SAVE A LONGFORM VERSION OF YOUR DATA
write_csv(data,"longform_data.csv")
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
#
# data_summ = data %>%
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#filter for US, English, na, and duplicate, then get scores
###TODO: add filter for filler.left and filler.right??
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(Answer.English == "yes" &
Answer.country == "USA" &
Answer.profcheck1 == "Yes" &
Answer.profcheck2 == "Yes" &
TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating)) %>%
select(-Answer.English, -Answer.country, -Answer.profcheck1, -Answer.profcheck2,
-na.pct, -n)
write_csv(data.good,"good_data.csv")
data.good.summary = data.good %>%
group_by(Item, Plausibility, Voice) %>%
summarize(
m = mean(Answer.Rating),
stdev= sd(Answer.Rating),
#    se = stdev/sqrt(n()),
#    upper= m+se*1.96,
#    lower=m-se*1.96
)
write_csv(data.good.summary[order(data.good.summary$Item),],
"EventsRev_data_summ.csv")
source('D:/git/beh-ratings-events/2_EventsAdapt_plausibility/analyses/analyze_subjects.R', echo=TRUE)
source('D:/git/beh-ratings-events/2_EventsAdapt_plausibility/analyses/analyze_subjects.R', echo=TRUE)
source('D:/git/beh-ratings-events/2_EventsAdapt_plausibility/analyses/analyze_subjects.R', echo=TRUE)
